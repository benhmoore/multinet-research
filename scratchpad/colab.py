"""NN as FlowNet Multi-Layer Supra Adj pymnet MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HRkSmDD9eQj22ZrI466XlIThlBr9eJ5F

**MLP and sin, cos, exp, polynomial, square root, Gaussian, XOR**

Define MLP classes
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
import random


class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size_1)
        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)
        self.fc3 = nn.Linear(hidden_size_2, output_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        out = self.relu(out)
        out = self.fc3(out)
        return out


"""Initialize"""

input_size = 1
hidden_size_1 = 20
hidden_size_2 = 20
output_size = 1
hidden_size_xor = 20  # TODO

"""Helpers functions for MLP"""


def generate_data(func, low=-np.pi, high=np.pi, samples=2000):
    x = torch.linspace(low, high, samples).view(-1, 1)
    y = func(x)
    return x, y


def generate_xor_data(samples=2000):  # TODO
    # Generate XOR data
    x = torch.randint(2, (samples, 2)).float()
    y = (x.sum(dim=1) == 1).float().view(-1, 1)
    return x, y


def train_model(model, x, y, epochs=10000):
    criterion = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01)
    for epoch in range(epochs):
        model.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        if epoch % 1000 == 0:
            print("Epoch {}, Loss {:.4f}".format(epoch, loss.item()))
    return model


def evaluate_model(model, x, y):
    y_pred = model(x)
    mse_loss = nn.MSELoss()(y_pred, y).item()
    r2 = r2_score(y.detach().numpy(), y_pred.detach().numpy())
    print("\nMSE Loss: ", mse_loss)
    print("R2 Score: ", r2)


def plot_predictions(func_name, model, x, y):
    y_pred = model(x)
    plt.figure(figsize=(10, 5))
    plt.plot(x.detach().numpy(), y.detach().numpy(), label="True function")
    plt.plot(x.detach().numpy(), y_pred.detach().numpy(), label="MLP predictions")
    plt.legend()
    plt.show()


def MLP_get_weights(model):
    weights_dict = {}
    i = 1
    for layer in model.children():
        if isinstance(layer, nn.Linear):
            weight_matrix = layer.weight.data
            weight_matrix = weight_matrix.detach().numpy()
            weights_dict["weights_layer{}".format(i)] = weight_matrix
            i += 1
    return weights_dict


def plot_graph_and_spectral_density(G, adj_matrix):
    plt.figure()
    pos = nx.spring_layout(G)
    nx.draw(
        G, pos, with_labels=True, node_color="skyblue", node_size=500, edge_color="k"
    )
    labels = nx.get_edge_attributes(G, "weight")
    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)
    plt.title("Graph with {} nodes".format(G.number_of_nodes()), fontsize=15)
    plt.show()

    eigenvalues = np.linalg.eigvalsh(adj_matrix)
    plt.scatter(eigenvalues, [0] * len(eigenvalues))
    plt.show()

    plt.figure()  # Create a new figure
    print("Spectral Density")
    density, bins, _ = plt.hist(eigenvalues, bins="auto", density=True)
    plt.show()


def MLP_to_non_supra_adjacency_matrix(adj_matrix):
    dim = adj_matrix.shape[0]
    original_order = list(range(dim))
    new_order = original_order.copy()
    random.shuffle(new_order)
    shuffled_adj_matrix = adj_matrix[:, new_order][new_order]
    G = nx.from_numpy_array(shuffled_adj_matrix, create_using=nx.DiGraph)
    for i, j in G.edges():
        G[i][j]["weight"] = shuffled_adj_matrix[i, j]
    print("Undirected Non-Supra Adjacency Matrix")
    plot_graph_and_spectral_density(G, shuffled_adj_matrix)


def MLP_to_supra_adjacency_matrix(model):
    weights = MLP_get_weights(model)
    weights_layer1 = np.round(weights["weights_layer1"], 2).astype(str)
    weights_layer2 = np.round(weights["weights_layer2"], 2).astype(str)
    weights_layer3 = np.round(weights["weights_layer3"], 2).astype(str)
    G = nx.DiGraph()
    G.add_node(0)
    for i, weight in enumerate(weights_layer1, start=1):
        G.add_node(i)
        G.add_edge(0, i, weight=float(weight))

    num_nodes = G.number_of_nodes()
    for i, row_weights in enumerate(weights_layer2, start=1):
        for j, weight in enumerate(row_weights, start=num_nodes):
            if not G.has_node(j):
                G.add_node(j)
            G.add_edge(i, j, weight=float(weight))

    num_nodes = G.number_of_nodes()
    G.add_node(num_nodes)
    for i, weight in enumerate(
        weights_layer3[0], start=num_nodes - weights_layer3.shape[1]
    ):
        G.add_edge(i, num_nodes, weight=float(weight))
    G = G.to_undirected()
    adj_matrix = nx.to_numpy_array(G)
    print("Undirected Supra Adjacency Matrix")
    plot_graph_and_spectral_density(G, adj_matrix)
    MLP_to_non_supra_adjacency_matrix(adj_matrix)


def MLP_matrix_representation(model):
    matrix_representation = []
    for layer in model.children():
        if isinstance(layer, nn.Linear):
            weight_matrix = layer.weight.data
            weight_matrix = weight_matrix.detach().numpy()
            matrix_representation.append(weight_matrix)
    return matrix_representation


def print_and_save_heatmap(matrices, suffix):
    for i, matrix in enumerate(matrices):
        print(f"Matrix for layer {i+1}:\n")
        plt.figure(figsize=(8, 8))
        sns.heatmap(matrix, cmap="coolwarm", center=0)
        plt.title(f"{suffix}_Adjacency Matrix for Layer {i+1}")
        plt.savefig(f"{suffix}_layer_{i+1}_adjacency_matrix.png")
        plt.show()


def run_experiment(func_name, func, model_class=MLP):
    model = model_class()
    print(f"=== {func_name} ===")
    x, y = generate_data(func)
    print("Training model...")
    model = train_model(model, x, y)
    print("Evaluating model...")
    evaluate_model(model, x, y)
    plot_predictions(func_name, model, x, y)
    print("Converting MLP to matrices...")
    matrix_representation = MLP_matrix_representation(model)
    print_and_save_heatmap(matrix_representation, func_name)
    print("Converting MLP to Supra Adjacency Matrix...")
    MLP_to_supra_adjacency_matrix(model)
    print("\n\n")


run_experiment("sin", torch.sin)
run_experiment("cos", torch.cos)
run_experiment("exp", torch.exp)
run_experiment("polynomial", lambda x: 3 * x**3 - 2 * x**2 + x - 1)
run_experiment("square root", torch.sqrt)
run_experiment("Gaussian", lambda x: torch.exp(-(x**2)))
